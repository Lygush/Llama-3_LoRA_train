# –¢–æ–Ω–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ LLM —Å –ø–æ–º–æ—â—å—é LoRA

## üîç –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏
- üöÄ –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ LoRA
- üìä –û—Ü–µ–Ω–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ (ROUGE-1/2/L)
- üíæ –ê–≤—Ç–æ–∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- üìà –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –æ–±—É—á–µ–Ω–∏—è
- üß† –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏ (RAM-–¥–∏—Å–∫, –æ—á–∏—Å—Ç–∫–∞ CUDA)
- ‚èØÔ∏è –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è

## ‚ö° –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç
1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:
   pip install -r lora_train/requirements.txt

2. –ü–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSONL:
    ```
   –§–∞–π–ª: train_dataset.jsonl
   –§–æ—Ä–º–∞—Ç –∑–∞–ø–∏—Å–µ–π:
   {"messages": [
        {"role": "system", "content": "..."},
        {"role": "user", "content": "..."},
        {"role": "assistant", "content": "..."}
   ]}
    ```
3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ:
   python main.py

## ‚öôÔ∏è –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
```
–ü–∞—Ä–∞–º–µ—Ç—Ä             –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é                –û–ø–∏—Å–∞–Ω–∏–µ
------------------- ------------------------------------- ----------------------------------
MODEL_PATH          "meta-llama/Llama-3.1-8B-Instruct"    –ü—É—Ç—å/–∏–º—è –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏
DATASET_PATH        "train_dataset.jsonl"                 –ü—É—Ç—å –∫ –æ–±—É—á–∞—é—â–µ–º—É –¥–∞—Ç–∞—Å–µ—Ç—É
LORA_RANK           32                                    –†–∞–Ω–≥ –º–∞—Ç—Ä–∏—Ü LoRA
LORA_ALPHA          64                                    –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è LoRA
MAX_SEQ_LENGTH      328                                   –ú–∞–∫—Å. –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
VALIDATION_SPLIT    0.03                                  –î–æ–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
USE_RAMDISK         False                                 –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å RAM-–¥–∏—Å–∫ –¥–ª—è –¥–∞–Ω–Ω—ã—Ö
```
## üìÇ –í—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
```
–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è         –°–æ–¥–µ—Ä–∂–∏–º–æ–µ
----------------- ----------------------------------------------------------
lora_out/          –ß–µ–∫–ø–æ–∏–Ω—Ç—ã –æ–±—É—á–µ–Ω–∏—è –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
ready_lora/        –§–∏–Ω–∞–ª—å–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
training_logs/     –õ–æ–≥–∏ –∫–æ–Ω—Å–æ–ª–∏ –∏ –º–µ—Ç—Ä–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è
dataset_cache/     –ö—ç—à —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
```
## ‚ö° –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
- –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø—Ä–∏–º–µ—Ä–æ–≤ –ø–æ –¥–ª–∏–Ω–µ —Ç–æ–∫–µ–Ω–æ–≤
- –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ (batch size 18)
- XFormers –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è
- –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ (gradient accumulation)
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ CUDA
- –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

## ‚ÑπÔ∏è –ü—Ä–∏–º–µ—á–∞–Ω–∏—è
- –°–∫—Ä–∏–ø—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å GPU RTX5060Ti 16Gb
- –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —á–µ–∫–ø–æ–∏–Ω—Ç–∞
- –í–∫–ª—é—á–∞–µ—Ç –Ω–∞—á–∞–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–æ –æ–±—É—á–µ–Ω–∏—è
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ—à–∏–±–∫–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö

## üìä Metrics Dashboard (–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ)
–î–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –º–µ—Ç—Ä–∏–∫ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ:
python metrics_dashboard.py --metrics-file training_logs/training_metrics.jsonl

–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –¥–∞—à–±–æ—Ä–¥–∞:
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ –º–µ—Ç—Ä–∏–∫
- –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤:
  ‚Ä¢ Training/Validation Loss
  ‚Ä¢ Learning Rate
  ‚Ä¢ Gradient Norm
- –ß–∞—Å—Ç–æ—Ç–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: 5 —Å–µ–∫—É–Ω–¥
